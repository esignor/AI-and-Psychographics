{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkT2sRmE_Ct-"
   },
   "source": [
    "# BIG FIVE Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aT7wuyVHCi_2"
   },
   "source": [
    "### WORD AND PHRASE CORRELATIONS\n",
    "Instantiating the model **Word and phrase correlations model** `[2: H. Andrew Schwartz, Johannes C. Eichstaedt, Margaret L. Kern, Lukasz\n",
    "Dziurzynski, Stephanie M. Ramones, Megha Agrawal, Achal Shah, Michal\n",
    "Kosinski, David Stillwell, Martin EP Seligman, Lyle H. Ungar. 2013 Personality, Gender, and Age in the Language of Social Media: The Open-\n",
    "Vocabulary Approach.]`, `[4: M. L. Kern, J. C. Eichstaedt, H. A. Schwartz, L. Dziurzynski, L. H. Ungar, D. J. Stillwell, M. Kosinski, S. M. Ramones, M. E. P. Seligman. 2014. The Online Social Self: An Open Vocabulary Approach to Personality]`.\n",
    "\n",
    "The model is based on differential language analysis (DLA) - Open Vocabulary. It is based on tree key characteristics:\n",
    "1. Linguistic Feature Extraction\n",
    "<center> $p(phrase|subject) = \\large{\\frac{freq(phrase, subject)}{\\sum_{phrase' \\in vocab(subject)} freq(phrase', subject)}}$ </center>\n",
    "\n",
    "> where vocab(subject) returns a list of all words and phrases used by the subject\n",
    "\n",
    "<center> $p(topic|subject) = \\sum_{word \\in topic} p(topic|word) * p(word|subject)$ </center>\n",
    "\n",
    "> where p(word|subject) is the subject's use of the normalised word; p(topic|word) is the probability of the argument given the word\n",
    "\n",
    "2. Correlational Analysis: using ordinary least squares regression\n",
    "\n",
    "3. Visualization: with word clouds that resize the size of words according to their frequency;  and based on the strength of the correlation of the word with the demographic and psychological measurement of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c54hvjCRDtYs"
   },
   "source": [
    "#### Big-Five prediction\n",
    "* To predict a user's personality, the incidence rate of: Extroversion, Conscientiousness, Openness to Experience, Agreeableness and Neuroticism (High and Low respectively). To do this I therefore used the `top100.1to3grams.gender_age_controlled.rmatrix` [2][4] models of each of the personality traits. Having the correlation between each phrase and personality trait in the models (ordinary least squares linear regression, with significance at a Bonferroni corrected p < 0.001), I decided to use it to predict the high and low traits of each 'user_id':\n",
    "\n",
    "<center>$\\overline{correlation}(category|document) = \\large{\\frac{\\sum_{phrase \\in category} correlation(phrase, document)}{n}}$</center>\n",
    "\n",
    "> where $correlation(phrase, document)$ is the correlation of the phrase when all $words \\in phrase$ are present in the document in some order; n is the number of correlations found in document $(|\\sum_{phrase \\in category} correlation(phrase, document)|)$. \n",
    "\n",
    "* For the case study **female neuroticism for mathematics** `[56: M. Lunardon, T. Cerni, R. I. Rumiati. 2022. Numeracy Gender Gap in STEM Higher Education: The Role of Neuroticism and Math Anxiety]`, I consider:\n",
    "\n",
    "\n",
    "> 1.  a document is the user (meaning as Bag-Of-Words)\n",
    "2. $\\overline{correlation}(category|user) = \\large{\\frac{\\sum_{phrase \\in category} correlation(phrase, user)}{n}} $ = $\\large{\\frac{\\sum_{phrase \\in category} correlation(phrase, user)}{|\\sum_{phrase \\in category} correlation(phrase, user)|}}$, with $category = \\{A, C, E, N, O\\}$\n",
    "3. ($phrase \\in category$) match with ($phrase \\in user$) $\\quad$ if $\\quad$  ($\\forall$ $word \\in phrase)\\in  category$ then $word \\in BOW_{user}$ for $user \\in User\\_id$\n",
    "\n",
    "* The dataset on which to Big-Five personality prediction is `BAG-OF-WORDS DATASET`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OJZTRm4We8g"
   },
   "source": [
    "### CONFIGURATION\n",
    "\n",
    "#### Libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "K3M3Nxi4WgSj"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92Qv3RXiW-4s"
   },
   "source": [
    "#### Project Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1951,
     "status": "ok",
     "timestamp": 1670067830821,
     "user": {
      "displayName": "Eleonora Signor",
      "userId": "04561396956553626752"
     },
     "user_tz": -60
    },
    "id": "OapX3yaLXMau",
    "outputId": "10a05f4a-7937-47e6-ab25-e59f47ad5467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eleonora/Desktop/TESI Code\n",
      "'BAG-OF-WORDS DATASET.ipynb'   OLD\n",
      "'BIG FIVE Model.ipynb'\t       RESULTS\n",
      " DATASETS\t\t      'TWITTER OCCUPATION DATASET'\n",
      "'GENDER Model.ipynb'\t      'WORD CLOUDS'\n",
      " MODELS\n"
     ]
    }
   ],
   "source": [
    "%cd \"/home/eleonora/Desktop/TESI Code\" \n",
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHfBOebXXLzs"
   },
   "source": [
    "### BAG-OF-WORDS DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ce0a9-3kXq-s"
   },
   "source": [
    "*BAG-OF-WORDS DATASET* allows me to obtain for each user of `Twitter Occupation Dataset` a .csv file of its Bag-Of-Words, in which:\n",
    "- column 1: key\n",
    "- column 2: user_id\n",
    "- column 3: data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tU8fp027eq5H"
   },
   "outputs": [],
   "source": [
    "# path of BAG-OF-WORDS DATASET\n",
    "path_BOWs_DATASET = \"./DATASETS/BAG-OF-WORDS DATASET.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the file `BAG-OF-WORDS DATASET.csv` I instantiate the `df_BOWs` dataframe as its identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fFKKbgWAXqNQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        user_id                                               data\n",
      "key                                                               \n",
      "0     206749819  \"#1\":0.0003209757663296421:2 \"#12\":0.000160487...\n",
      "1     706405455  \"#20\":3.470173855710171e-05:1 \"#25\":3.47017385...\n",
      "2     185699053  \"#1\":0.0004828585224529213:1 \"#2\":0.0009657170...\n",
      "3    1134832688  \"#\":0.00026518164942985947:4 \"#9\":6.6295412357...\n",
      "4      36040783  \"#\":6.967670011148272e-05:1 \"#1\":0.00034838350...\n"
     ]
    }
   ],
   "source": [
    "df_BOWs  = pd.read_csv(path_BOWs_DATASET)\n",
    "new_index  = df_BOWs['Unnamed: 0']\n",
    "df_BOWs = df_BOWs[['user_id', 'data']]\n",
    "df_BOWs = df_BOWs.set_index(new_index)\n",
    "df_BOWs = df_BOWs.rename_axis(\"key\")\n",
    "print(df_BOWs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTlATbZLZexl"
   },
   "source": [
    "> *Example: user 206749819 in his Twitter posts made use of word '#1' with a word frequency ratio over all words of 0.000320976 and 2 frequency, word '#12' with a 0.000160488 ratio and 1 frequency, word '#17' with a 0.000160488 ratio and 2 frequency, and so on.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few printouts of the dataframe contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 185699053 \n",
      "word: \"#1\" \n",
      "x_word: 0.000483 \n",
      "freq: 1 \n"
     ]
    }
   ],
   "source": [
    "user_id  = (df_BOWs.iloc[2])[0] # user_id\n",
    "data_user = (df_BOWs.iloc[2])[1] # data for user 'user_id'\n",
    "data_line = data_user.split(' ') # BOW of 'user_id'\n",
    "data_entry = data_line[0].split(':') # first word of user_id\n",
    "\n",
    "print(\"user_id: %s \" % user_id)\n",
    "print(\"word: %s \" % data_entry[0])\n",
    "print(\"x_word: %f \" % float(data_entry[1]))\n",
    "print(\"freq: %i \" % int(data_entry[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of lines present in the dataframe, except the header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers lines present in BOWs DATASET: 5189\n"
     ]
    }
   ],
   "source": [
    "TOT_users = int(df_BOWs['user_id'].shape[0])\n",
    "print(\"Numbers lines present in BOWs DATASET: %i\" %TOT_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfCPrIW_v6y-"
   },
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method that transform  personality model in dictionairy {word_dic, correlation_dic}\n",
    "\n",
    "def transformInDict(personality_modelLines):\n",
    "        dic_peronalityModel = dict()\n",
    "        for i, line in enumerate(personality_modelLines):\n",
    "        if i >= 1: # avoid header\n",
    "            dic = line.split(\",\"); \n",
    "            word_dic = dic[0].strip('\"') # key\n",
    "            correlation_dic = dic[1].strip('\"') # value\n",
    "            dic_personalityModel.update({word_dic : correlation_dic})\n",
    "            \n",
    "    return dic_personalityModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method that return the content of \"./MODELS/BF/\" as list of dictionaries\n",
    "\n",
    "def extract_personalityModels(keywords_personality):\n",
    "    personality_dictList = list()\n",
    "    for k, key in enumerate(keywords_personality):\n",
    "        personality = open(\"./MODELS/BF/\"+key+\".top100.1to3grams.gender_age_controlled.rmatrix.csv\", \"r\")\n",
    "        personality_modelLines = personality.readlines() \n",
    "        personality_modelLinesList.append(transformInDict(personality_modelLines))\n",
    "        personality.close()\n",
    "\n",
    "    return personality_dictList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYOKKGagUGLG"
   },
   "outputs": [],
   "source": [
    " # method that search math between phrase and words in BOW after the first\n",
    "\n",
    " def matchWord_phrase(idx_phrase, phrase_bf, aux, user_id, count_word):\n",
    "    for i in range(0, count_word): # for each [word, x_word, freq_word] for user_id 'key'\n",
    "        data_entry = data_line[i].split(':') # i entry in BOW of 'key' user_id\n",
    "        word_bow = str(data_entry[0])\n",
    "        word = re.sub('\"', \"\", word_bow)\n",
    "                \n",
    "      \n",
    "        if word_bow == phrase_bf[idx_phrase]:\n",
    "        if idx_phrase == len(phrase_bf) - 1: # effettive match between BOW_user and phrase (complete match)\n",
    "            aux.append(word_bow)\n",
    "            return True, aux \n",
    "        else: # partial match\n",
    "            match, aux = matchWord_phrase(idx_phrase+1, lines_bow,  phrase_bf, aux, count_word)\n",
    "            if match:\n",
    "                aux.append(word_bow)\n",
    "                return True, aux\n",
    "            else:\n",
    "                return False, aux\n",
    "\n",
    "  return False, aux # no match found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvpPAKuz8EpE"
   },
   "outputs": [],
   "source": [
    "# method that return the phrase and its correlation, if exist, in category\n",
    "\n",
    "def personalityPhrase(line, j):\n",
    "  \n",
    "  if j >= 1 and len(line) > 3: # avoid case , ,\n",
    "    bf = line.split(','); \n",
    "    phrase_bf = (bf[0].strip('\\n')) # select phrase in personality model\n",
    "\n",
    "    if '\"' in phrase_bf:\n",
    "      phrase_bf = phrase_bf.replace('\"\"', '\"')\n",
    "      phrase_bf = phrase_bf[1:-1]\n",
    "\n",
    "        \n",
    "    if len(phrase_bf) == 0:\n",
    "      phrase_bf = '\"'\n",
    "\n",
    "    # special case line \"_,\", _, _, (e.g., the lord, \"A\")\n",
    "    next = 1\n",
    "    if bf[next] == '\"':\n",
    "      next += 1\n",
    "      phrase_bf = bf[0] + \",\"\n",
    "      phrase_bf = phrase_bf[1:]\n",
    " \n",
    "    correlation = float((bf[next].strip('\\n'))) # phrase correlation in personality model\n",
    "    return phrase_bf, correlation\n",
    "\n",
    "  return None, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3d7xhjJRM0u"
   },
   "outputs": [],
   "source": [
    "# method for computation sum_{phrase \\in category} correlation(phrase, user) for each category, for 'user_id'\n",
    "\n",
    "def sumBOWUserCorrCategoryPersonalityWords(personality_dictList, user_id):\n",
    "    norma_correlationList = list()\n",
    "    supportList = list()\n",
    "\n",
    "    for k, personality_dict in enumerate(personality_dictList): # for each trait personality\n",
    "        occuranceModelMatch = 0\n",
    "        sum_correlation = 0\n",
    "        \n",
    "        data_user = (df_BOWs.iloc[key])[1] # data column for user_id 'key'\n",
    "        data_line = data_user.split(' ') # BOW of user_id 'N_user'\n",
    "        count_word = int(len(data_line))\n",
    "    \n",
    "        for phrase in personality_dict.keys():\n",
    "            for i in range(0, count_word): # for each [word, x_word, freq_word] for user_id 'key'\n",
    "                data_entry = data_line[i].split(':') # i entry in BOW of 'key' user_id\n",
    "                word_bow = str(data_entry[0])\n",
    "                word = re.sub('\"', \"\", word_bow)\n",
    "                \n",
    "        # (pharase ∈ category) match with (pharase ∈ vocab(user))    if    (∀ word ∈ phrase) ∈ BOWuser  for some  user ∈ User_id\n",
    "                aux = []\n",
    "                if word_bow == phrase[0]: # phrase is a word (first match)\n",
    "                    aux.append(phrase[0])\n",
    "                    if 0 == len(phrase) - 1: # effettive match between BOW_user and phrase (complete match)\n",
    "                        match = True\n",
    "                    else: # partial match\n",
    "                        match, aux = matchWord_phrase(1, phrase, aux, count_word)\n",
    "                        \n",
    "                    if match: # for each match\n",
    "                        occuranceModelMatch += 1\n",
    "                        sum_correlation += personality_dict.get(phrase) # the correlation is only in the phrase (is sufficient do computation in the first partial match)\n",
    "                        #if correlation >= 0.0:\n",
    "                            #print(\"positive %s %s %f\" %(phrase, aux, correlation))\n",
    "                        #else:\n",
    "                            #print(\"negative %s %s %f\" %(phrase, aux, correlation))\n",
    "\n",
    "        if occuranceModelMatch != 0:\n",
    "            norma_correlationList.insert(k, float(sum_correlation / occuranceModelMatch))\n",
    "        else: # none correlations for j trait personality\n",
    "            norma_correlationList.insert(k, 0)\n",
    "\n",
    "        supportList.insert(k, (occuranceModelMatch * 100) / count_word)\n",
    "\n",
    "    return supportList, norma_correlationList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtxjBM3qtWsL"
   },
   "outputs": [],
   "source": [
    "# method that computation the mean of values belonging to list \n",
    "\n",
    "def mean_statistics(list, len):\n",
    "  mean_list = 0\n",
    "  for l in list:\n",
    "    mean_list += l\n",
    "\n",
    "  return float(mean_list / len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-fF0haaJjtIU"
   },
   "outputs": [],
   "source": [
    "# method that define the sum_{phrase \\in category} correlation(phrase, user) for each trait of personality; and return the dataframe with these correlations\n",
    "\n",
    "def resultsPredictionPersonality(supportList, norma_correlationList, user_id, highlow_traits): \n",
    "    ## computation mean correlation and mean support\n",
    "    mean_correlation = mean_statistics(norma_correlationList, len(norma_correlationList))\n",
    "    mean_support = mean_statistics(supportList, len(supportList))\n",
    "\n",
    "    return pd.DataFrame([[norma_correlationList[0], supportList[0], norma_correlationList[1], supportList[1], norma_correlationList[2], supportList[2], norma_correlationList[3], supportList[3], \n",
    "                      norma_correlationList[4], supportList[4], mean_correlation, mean_support, highlow_traits]], \n",
    "                      columns = [\"A norma-correlation\", \"A support (%)\", \"C norma-correlation\", \"C support (%)\", \"E norma-correlation\", \"E support (%)\", \"N norma-correlation\", \"N support (%)\",\n",
    "                     \"O norma-correlation\", \"O support (%)\", \"mean correlation\", \"mean support (%)\", \"high/low traits\"], index = [user_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R52VSZopDiEb"
   },
   "outputs": [],
   "source": [
    "# method that define the high/low traits of personality for 'user_id'; and return the dataframe with this traits, if exist\n",
    "\n",
    "def highLowTraitPersonality(norma_correlationList, user_id):\n",
    "  A = norma_correlationList[0]\n",
    "  C = norma_correlationList[1]\n",
    "  E = norma_correlationList[2]\n",
    "  N = norma_correlationList[3]\n",
    "  O = norma_correlationList[4]\n",
    "\n",
    "  # - low extroversion: [-0.089 to -0.036]\n",
    "  # - high extroversion: [0.059 to 0.111]\n",
    "  # - low agreeableness: [-0.123 to -0.034]\n",
    "  # - high agreeableness: [0.032 to 0.059]\n",
    "  # - low conscientiousness: [-0.105 to -0.039]\n",
    "  # - high conscientiousness: [0.035 to 0.069]\n",
    "  # - low emotional stability: [-0.086 to -0.042]\n",
    "  # (- high neuroticism: [0.042 to 0.086])\n",
    "  # - high emotional stability: [0.023 to 0.047]\n",
    "  # (- low neuroticism: [-0.047 to -0.023])\n",
    "  # - low openness: [-0.090 to -0.039]\n",
    "  # - high openness: [0.072 to 0.124]\n",
    "  \n",
    "    highlow_traits = \"\"\n",
    "    if A >= -0.123 and A <= -0.034:\n",
    "        highlow_traits += \"LA \"\n",
    "    if A >= 0.032 and A <= 0.059:\n",
    "        highlow_traits += \"HA \"\n",
    "\n",
    "    if C >= -0.105 and C <= -0.039:\n",
    "        highlow_traits += \"LC \" \n",
    "    if C >= 0.035 and C <= 0.069:\n",
    "        highlow_traits += \"HC \"\n",
    "\n",
    "    if E >= -0.089 and E <= -0.036:\n",
    "        highlow_traits += \"LE \"\n",
    "    if E >= 0.059 and E <= 0.111:\n",
    "        highlow_traits += \"HE \"\n",
    "\n",
    "    if O >= -0.090 and O <= -0.039:\n",
    "        highlow_traits += \"LO \"\n",
    "    if O >= 0.072 and O <= 0.124:\n",
    "        highlow_traits += \"HO \"\n",
    "\n",
    "    if N >= -0.047 and N <= -0.023:\n",
    "        highlow_traits += \"LN \"\n",
    "    if N >= 0.042 and N <= 0.086:\n",
    "        highlow_traits += \"HN \"\n",
    "        \n",
    "    highlow_traits = highlow_traits[:-1] # remove last character (\" \")\n",
    "    return highlow_traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-d_KdJ66pcs"
   },
   "outputs": [],
   "source": [
    "# main method for pedict trait personality for each user\n",
    "\n",
    "def prediction_personality(keywords_personality):\n",
    "    path_csv = \"./RESULTS/Predictions BIG FIVE Model.csv\"\n",
    "    \n",
    "    personality_dictList = extract_personalityModels(keywords_personality)\n",
    "\n",
    "    df_outBF = pd.DataFrame()\n",
    "    \n",
    "    ## extract user_id and computation dot product (w_f * x_f) between personality models and BOWs DATASET\n",
    "    for key in range(0, TOT_users): # extract user_id\n",
    "        user_id = int((df_BOWs.loc[key])['user_id'])\n",
    "        \n",
    "        ##  sum_{phrase \\in category} correlation(phrase, user) for each category/trait\n",
    "        supportList, norma_correlationList = sumBOWUserCorrCategoryPersonalityWords(personality_dictList, user_id)\n",
    "        highlow_traits = highLowTraitPersonality(norma_correlationList, user_id)\n",
    "        \n",
    "        ## print result trait personality for user_id in Predictions BIG FIVE Model\n",
    "        df_outBF = pd.concat([df_outBF, resultsPredictionPersonality(supportList, norma_correlationList, user_id, highlow_traits)]\n",
    "        # if N_user == 500: break\n",
    "                             \n",
    "    return df_outBF, df_outHL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method that transform in 'Prediction BIG FIVE Model.csv' and 'Low High Personality Traits BIG FIVE Model.csv' dframe prediction personality\n",
    "\n",
    "def outRESULT(path_resultcsv, df_outGender):\n",
    "    df_outBF.to_csv(path_csv) \n",
    "    df_outHL.to_csv(path_)  \n",
    "    print(\"'Prediction BIG FIVE Model.csv' successfully created\")\n",
    "    print(\"'Low High Personality Traits BIG FIVE Model.csv' successfully created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iR6F9x_Uv_3G"
   },
   "source": [
    "### MAIN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0-HNjBxwOYd"
   },
   "source": [
    "Big Five Predictions with Low and High traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4831891,
     "status": "ok",
     "timestamp": 1669903806443,
     "user": {
      "displayName": "Eleonora Signor",
      "userId": "04561396956553626752"
     },
     "user_tz": -60
    },
    "id": "Rg9jT_PZFdav",
    "outputId": "fe641d17-94d2-46fa-ce13-d48482207677"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Prediction BIG FIVE Model.csv' successfully created\n",
      "'Low High Personality Traits BIG FIVE Model.txt' successfully created\n"
     ]
    }
   ],
   "source": [
    "keywords_personality = [\"A\", \"C\", \"E\", \"N\", \"O\"]\n",
    "prediction_personality(keywords_personality)\n",
    "### calculation of efficiency (read files): 1 create_outputCSV + 1 create_outputTraitsText + 5 extract_personalityModels + 1 user_id + |user_id| sumBOWUserCorrCategoryPersonalityWords + |user_id| print_resultsPredictionPersonality + |user_id| print_highlowTraitPersonalit"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPU+U0RP1ZeVmtfUjYmC0UC",
   "mount_file_id": "1e5b-2Kn0IS47EKCjljf39C6IwZ9hjWHF",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
